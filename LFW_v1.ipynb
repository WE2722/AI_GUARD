{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e376c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dlib models...\n",
      "Dlib models loaded successfully.\n",
      "Loaded 38028 enrolled embeddings for 5661 unique individuals.\n",
      "\n",
      "Starting AI Guard System. Press 'q' to quit.\n",
      "Using recognition threshold: 0.55\n",
      "Webcam/Video FPS: 30.0\n",
      "Webcam/Video Resolution: 640x480\n",
      "Quitting...\n",
      "AI Guard System stopped.\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt # Optional, for debugging specific frames if needed\n",
    "\n",
    "# --- 1. Load Dlib Models (Local Paths) ---\n",
    "DLIB_MODELS_PATH = r\"C:\\Users\\Wiam\\Desktop\\AI_Guard\\Dlib_face_recognition\" # Current directory, assuming .dat files are here\n",
    "# Or specify a subfolder if you put them there, e.g., \"models/\"\n",
    "landmark_predictor_file = \"shape_predictor_68_face_landmarks.dat\"\n",
    "face_recognition_model_file = \"dlib_face_recognition_resnet_model_v1.dat\"\n",
    "\n",
    "landmark_predictor_path = os.path.join(DLIB_MODELS_PATH, landmark_predictor_file)\n",
    "face_recognition_model_path = os.path.join(DLIB_MODELS_PATH, face_recognition_model_file)\n",
    "\n",
    "if not (os.path.exists(landmark_predictor_path) and os.path.exists(face_recognition_model_path)):\n",
    "    print(f\"ERROR: Dlib model files not found. Searched in '{os.path.abspath(DLIB_MODELS_PATH)}'\")\n",
    "    print(f\"Ensure '{landmark_predictor_file}' and '{face_recognition_model_file}' are in that location.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    print(\"Loading Dlib models...\")\n",
    "    face_detector = dlib.get_frontal_face_detector() \n",
    "    landmark_predictor = dlib.shape_predictor(landmark_predictor_path)\n",
    "    face_encoder = dlib.face_recognition_model_v1(face_recognition_model_path)\n",
    "    print(\"Dlib models loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dlib models: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Load Enrolled Data (Local Path) ---\n",
    "ENROLLMENT_FILE_PATH = r\"C:\\Users\\Wiam\\Desktop\\AI_Guard\\ai_guard_GENERATED_enrollments.pkl\" # Assuming it's in the same directory\n",
    "\n",
    "if not os.path.exists(ENROLLMENT_FILE_PATH):\n",
    "    print(f\"ERROR: Enrollment file not found at '{os.path.abspath(ENROLLMENT_FILE_PATH)}'\")\n",
    "    exit()\n",
    "try:\n",
    "    with open(ENROLLMENT_FILE_PATH, \"rb\") as f:\n",
    "        enrollment_data = pickle.load(f)\n",
    "    known_embeddings_db = enrollment_data[\"embeddings\"] \n",
    "    known_labels_db = enrollment_data[\"labels\"]         \n",
    "    print(f\"Loaded {known_embeddings_db.shape[0]} enrolled embeddings for {len(set(known_labels_db))} unique individuals.\")\n",
    "    if known_embeddings_db.shape[0] == 0:\n",
    "        print(\"ERROR: Enrollment database is empty!\")\n",
    "        exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading enrollment data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Recognition Parameters ---\n",
    "RECOGNITION_THRESHOLD = 0.55  # Start with this, TUNE IT!\n",
    "DLIB_UPSAMPLE_DETECT_REALTIME = 0 # Start with 0 for speed. Increase to 1 if missing faces.\n",
    "DLIB_JITTERS_ENCODE_REALTIME = 1  # Fewer jitters for speed.\n",
    "\n",
    "# --- 4. Alarm System ---\n",
    "last_alarm_time = 0\n",
    "ALARM_COOLDOWN_SECONDS = 5 # Cooldown for alarms\n",
    "alarm_active = False # State to keep alarm visually on for a bit\n",
    "\n",
    "# def play_alarm_sound(): # Optional\n",
    "#     try:\n",
    "#         from playsound import playsound\n",
    "#         # Make sure you have an alarm sound file (e.g., alarm.wav)\n",
    "#         # playsound(\"alarm.wav\") # Or use system beeps\n",
    "#         print(\"\\007\") # System beep (might not work on all systems/terminals)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not play sound: {e}\")\n",
    "\n",
    "def trigger_alarm(frame_to_save=None, unknown_person_count=0, recognized_person_on_watchlist=None):\n",
    "    global last_alarm_time, alarm_active\n",
    "    current_time = time.time()\n",
    "    \n",
    "    trigger_condition_met = False\n",
    "    reason = \"\"\n",
    "\n",
    "    if unknown_person_count > 0:\n",
    "        trigger_condition_met = True\n",
    "        reason = f\"{unknown_person_count} Unknown person(s) detected!\"\n",
    "    elif recognized_person_on_watchlist:\n",
    "        trigger_condition_met = True\n",
    "        reason = f\"WATCHLIST ALERT: {recognized_person_on_watchlist} detected!\"\n",
    "\n",
    "    if trigger_condition_met:\n",
    "        if (current_time - last_alarm_time) > ALARM_COOLDOWN_SECONDS:\n",
    "            print(f\"--- ALARM TRIGGERED ({time.strftime('%Y-%m-%d %H:%M:%S')}) ---\")\n",
    "            print(f\"  Reason: {reason}\")\n",
    "            # play_alarm_sound() # Optional\n",
    "            alarm_active = True # Set alarm state\n",
    "            last_alarm_time = current_time\n",
    "            \n",
    "            if frame_to_save is not None:\n",
    "                save_dir = \"alarm_snapshots\"\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                alarm_image_path = os.path.join(save_dir, f\"alarm_event_{timestamp}.jpg\")\n",
    "                cv2.imwrite(alarm_image_path, frame_to_save)\n",
    "                print(f\"  Snapshot saved to: {alarm_image_path}\")\n",
    "        return True # Indicates an alarm condition is active (new or recent)\n",
    "    \n",
    "    # Reset alarm_active visual state if cooldown has passed since it was set\n",
    "    if alarm_active and (current_time - last_alarm_time) > ALARM_COOLDOWN_SECONDS / 2: # Keep visual for half cooldown\n",
    "        alarm_active = False\n",
    "        \n",
    "    return False # No new alarm, or on cooldown for a new trigger\n",
    "\n",
    "# --- 5. Face Recognition Function for a Single Frame ---\n",
    "def recognize_faces_in_frame(frame, known_embeddings, known_labels):\n",
    "    # Frame should be BGR from OpenCV VideoCapture\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    detections = face_detector(img_rgb, DLIB_UPSAMPLE_DETECT_REALTIME)\n",
    "    recognized_people_in_frame = [] \n",
    "\n",
    "    for d_face in detections:\n",
    "        shape = landmark_predictor(img_rgb, d_face)\n",
    "        unknown_embedding = np.array(face_encoder.compute_face_descriptor(img_rgb, shape, DLIB_JITTERS_ENCODE_REALTIME))\n",
    "        distances = np.linalg.norm(known_embeddings - unknown_embedding, axis=1)\n",
    "        min_distance_idx = np.argmin(distances)\n",
    "        min_distance_val = distances[min_distance_idx]\n",
    "\n",
    "        name_recognized = \"Unknown\"\n",
    "        if min_distance_val < RECOGNITION_THRESHOLD:\n",
    "            name_recognized = known_labels[min_distance_idx]\n",
    "        \n",
    "        x1, y1, x2, y2 = d_face.left(), d_face.top(), d_face.right(), d_face.bottom()\n",
    "        recognized_people_in_frame.append(((x1, y1, x2, y2), name_recognized, min_distance_val))\n",
    "        \n",
    "    return recognized_people_in_frame\n",
    "\n",
    "# --- 6. Main Real-Time Loop ---\n",
    "# WATCHLIST_NAMES = {\"Some_Known_Person_To_Alert_For\"} # Example, use actual names from your labels\n",
    "WATCHLIST_NAMES = set() # Empty watchlist for now\n",
    "\n",
    "video_source = 0 # 0 for default webcam. Change if you have multiple or use a video file path.\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source: {video_source}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nStarting AI Guard System. Press 'q' to quit.\")\n",
    "print(f\"Using recognition threshold: {RECOGNITION_THRESHOLD}\")\n",
    "print(f\"Webcam/Video FPS: {cap.get(cv2.CAP_PROP_FPS)}\") # May not be accurate for all webcams\n",
    "print(f\"Webcam/Video Resolution: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\")\n",
    "\n",
    "\n",
    "frame_processing_interval = 3 # Process every Nth frame\n",
    "frame_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    frame_counter += 1\n",
    "    display_frame = frame.copy() # Work on a copy for display\n",
    "    alarm_triggered_for_this_cycle = False\n",
    "    \n",
    "    if frame_counter % frame_processing_interval == 0: # Process this frame\n",
    "        recognition_results = recognize_faces_in_frame(frame, known_embeddings_db, known_labels_db)\n",
    "        \n",
    "        unknowns_this_frame = 0\n",
    "        person_on_watchlist_detected = None\n",
    "\n",
    "        for (box, name, distance) in recognition_results:\n",
    "            x1, y1, x2, y2 = box\n",
    "            color = (0, 255, 0) # Green for known\n",
    "            \n",
    "            if name == \"Unknown\":\n",
    "                color = (0, 0, 255) # Red for unknown\n",
    "                unknowns_this_frame += 1\n",
    "            elif name in WATCHLIST_NAMES:\n",
    "                color = (0, 165, 255) # Orange for watchlist\n",
    "                person_on_watchlist_detected = name\n",
    "            \n",
    "            cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "            label_text = f\"{name} ({distance:.2f})\"\n",
    "            cv2.putText(display_frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        if unknowns_this_frame > 0 or person_on_watchlist_detected:\n",
    "            alarm_triggered_for_this_cycle = trigger_alarm(\n",
    "                frame_to_save=frame, # Save original frame for alarm\n",
    "                unknown_person_count=unknowns_this_frame,\n",
    "                recognized_person_on_watchlist=person_on_watchlist_detected\n",
    "            )\n",
    "\n",
    "    # Visual indicator for active alarm state (even if on cooldown for sound/new log)\n",
    "    if alarm_active: # 'alarm_active' is set by trigger_alarm\n",
    "        cv2.putText(display_frame, \"ALARM ACTIVE\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    else: # Check and potentially reset alarm_active if cooldown passed (handled in trigger_alarm too)\n",
    "         # but this explicit call makes sure it's reset if no new trigger happens\n",
    "        current_time_for_reset = time.time()\n",
    "        if (current_time_for_reset - last_alarm_time) > ALARM_COOLDOWN_SECONDS :\n",
    "             alarm_active = False\n",
    "\n",
    "\n",
    "    cv2.imshow('AI Guard - Live Surveillance', display_frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF # Wait for 1 ms\n",
    "    if key == ord('q'):\n",
    "        print(\"Quitting...\")\n",
    "        break\n",
    "    elif key == ord('a'): # Manual alarm trigger for testing\n",
    "        print(\"Manual alarm test!\")\n",
    "        trigger_alarm(frame_to_save=frame, unknown_person_count=1)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"AI Guard System stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de085106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
